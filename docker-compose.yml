# Этот файл реализует мониторинг логов приложений 
# используя кластер Elasticsearch 


version: '3'
services:
  # генерирует тестовый лог для проверки работоспособности системы
  # Проект https://git.rgwork.ru/ivlev/log-generator
  #
  # **log-generator** образует ротируемый лог logrus.log на диске , записи которого отсылаются
  # filebeat-ом в elk в сохраняются в индексе filebeat-*.
  # Настройки filebeat смотри в файле `configs/filebeat.yml`.
  # log-generator также отправляет новые записи лога напрямую в Эластик в
  # индекс logrus-*. См. код log-generator.
  log-generator:
    image: vadimivlev/log-generator:0.0.1
    container_name: log-generator
    restart: unless-stopped
    environment:
      # максимальная задержка добавления записей в лог
      - MAX_DELAY=5000
      # максимальное количество добавленных записей лога перед ротацией
      - MAX_RECORDS=10
      # имя файла лога внутри директории назначенной в параметре volumes:
      - LOG_FILE=logrus.log
      # адрес elasticsearch для прямой записи логов
      - ELASTIC_URL=http://es01:9200
      # хост elasticsearch для прямой записи логов
      - ELASTIC_HOST=es01
    volumes:
      - ./logs:/app/logs

  # следит за новыми файлами логов и посылает информацию о новых записях
  # согласно настройкам определенным в filebeat.yml
  log-monitor-filebeat:
    image: docker.elastic.co/beats/filebeat:7.7.0
    container_name: log-monitor-filebeat
    restart: unless-stopped
    volumes:
      # настроечный файл Filebeat
      - ./configs/filebeat.yml:/usr/share/filebeat/filebeat.yml
      # директория где Filebeat следит за файлами логов
      - ./logs:/logs
      # сертификат для связи с Logstash по SSL
      # - ./configs/logstash-beats.crt:/etc/pki/tls/certs/logstash-beats.crt
    # чтобы не сыпало ошибки на экран для output.console определенного в ./configs/filebeat.yml убрать -e
    #  и ослабить ограничения по доступу --strict.perms=false
    # https://www.elastic.co/guide/en/beats/libbeat/7.6/config-file-permissions.html
    command: filebeat -e --strict.perms=false


  # E L A S T I C S E A R C H   C L U S T E R  B E G I N -----------------------------------------------------------
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-log-monitor-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      # - cluster.initial_master_nodes=es01
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # добавить это к каждой службе эластик если свободного места на диске < 10%
      # в противном случае шарды не будут двигаться
      # - cluster.routing.allocation.disk.threshold_enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    # ports:
    #   - 9200:9200
    volumes:
      - data01:/usr/share/elasticsearch/data

  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-log-monitor-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
  
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-log-monitor-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data03:/usr/share/elasticsearch/data
  # E L A S T I C S E A R C H   C L U S T E R  E N D -----------------------------------------------------------
  
  
  
  # data visualization for elasticsearch
  kibana01:
    image: docker.elastic.co/kibana/kibana:7.7.0
    container_name: kibana01
    # ports:
    #   - 5601:5601
    environment:
      ELASTICSEARCH_HOSTS: '["http://es01:9200","http://es02:9200","http://es03:9200"]'
  
  # elasticsearch cluster visualization
  cerebro01:
    image: lmenezes/cerebro
    container_name: cerebro01
    # left to try through auth-proxy
    ports:
      - 9000:9000
    environment:
      CEREBRO_PORT: 9000
    

  # добавлен для базовой аутентификации поскольку Кибана не имеет собственной.
  # Параметры проксирования определены в Caddyfile
  log-monitor-caddy:
    # 0.10 TODO: change to latest version
    image: stefanprodan/caddy
    # 1.0.3
    # image: abiosoft/caddy
    # 2.0.0
    # image: caddy
    container_name: log-monitor-caddy
    restart: unless-stopped
    ports:
      - '9094:8080'
      - '9095:8081'
    volumes:
      - ./configs/Caddyfile:/etc/caddy/Caddyfile
    environment:
      - ADMIN_USER=${ADMIN_USER:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}


# volumes for elasticsearch data
volumes:
  data01:
  data02:
  data03:

# outer network to communicate with other services 
networks:
    default:
      external:
        name: auth_proxy_network
